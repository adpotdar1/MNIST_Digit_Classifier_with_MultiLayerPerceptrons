import torch
import torch.nn as nn
from torch import optim
from torchvision import transforms
from torchvision import datasets
from torch.utils.data import DataLoader
import torch.nn.functional as F
import matplotlib.pyplot as plt


transform = transforms.Compose(
    [
        transforms.ToTensor(),
        # Normalization is done to reduce values generated by multiplication of inputs and weights
        transforms.Normalize(mean=[0.5], std=[0.5])
    ]
)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)

training_data = datasets.MNIST(root='data', train=True, download=True)
test_data = datasets.MNIST(root='data', train=False, download=True, transform= transform)

training_loader = DataLoader(training_data, batch_size=32, shuffle=True)
test_loader = DataLoader(test_data, batch_size=32, shuffle=False)

def printSizeOfFirstElement(loader):
    #create iterator
    input_iter = iter(loader)

    # get to next item
    batch = next(input_iter)

    # separate inputs and labels
    inputs, labels = batch

    print(inputs[0].shape)

    # separate inputs

def print_first_few_images(dataset):
    image, label = dataset[0]

    # Print the image
    plt.imshow(image, cmap='gray')
    plt.title(f'Label: {label}')
    plt.show()

print_first_few_images(training_data)


#printSizeOfFirstElement(training_loader)


"""
Reducing number of outputs of first hidden layer, does not improve accuracy beyond 30 in 40 runs.

Adding another hidden layer still does not push accuracy above 30 after 40 runs.

"""